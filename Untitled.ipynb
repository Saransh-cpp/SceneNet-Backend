{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c2a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e19a1ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airport_inside',\n",
       " 'artstudio',\n",
       " 'auditorium',\n",
       " 'bakery',\n",
       " 'bar',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'bookstore',\n",
       " 'bowling',\n",
       " 'buffet',\n",
       " 'casino',\n",
       " 'children_room',\n",
       " 'church_inside',\n",
       " 'classroom',\n",
       " 'cloister',\n",
       " 'closet',\n",
       " 'clothingstore',\n",
       " 'computerroom',\n",
       " 'concert_hall',\n",
       " 'corridor',\n",
       " 'deli',\n",
       " 'dentaloffice',\n",
       " 'dining_room',\n",
       " 'elevator',\n",
       " 'fastfood_restaurant',\n",
       " 'florist',\n",
       " 'gameroom',\n",
       " 'garage',\n",
       " 'greenhouse',\n",
       " 'grocerystore',\n",
       " 'gym',\n",
       " 'hairsalon',\n",
       " 'hospitalroom',\n",
       " 'inside_bus',\n",
       " 'inside_subway',\n",
       " 'jewelleryshop',\n",
       " 'kindergarden',\n",
       " 'kitchen',\n",
       " 'laboratorywet',\n",
       " 'laundromat',\n",
       " 'library',\n",
       " 'livingroom',\n",
       " 'lobby',\n",
       " 'locker_room',\n",
       " 'mall',\n",
       " 'meeting_room',\n",
       " 'movietheater',\n",
       " 'museum',\n",
       " 'nursery',\n",
       " 'office',\n",
       " 'operating_room',\n",
       " 'pantry',\n",
       " 'poolinside',\n",
       " 'prisoncell',\n",
       " 'restaurant',\n",
       " 'restaurant_kitchen',\n",
       " 'shoeshop',\n",
       " 'stairscase',\n",
       " 'studiomusic',\n",
       " 'subway',\n",
       " 'toystore',\n",
       " 'trainstation',\n",
       " 'tv_studio',\n",
       " 'videostore',\n",
       " 'waitingroom',\n",
       " 'warehouse',\n",
       " 'winecellar']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('indoorCVPR_09/Images/*')\n",
    "categories = [folder.split(\"\\\\\")[-1] for folder in folders]\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc77783",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "label_no = 0\n",
    "for folder in folders:\n",
    "    if folder not in labels:\n",
    "        labels[folder] = label_no\n",
    "        label_no += 1\n",
    "        \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "vgg19.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8653ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 67)                1680963   \n",
      "=================================================================\n",
      "Total params: 21,705,347\n",
      "Trainable params: 1,680,963\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = Flatten()\n",
    "prediction_layer = Dense(len(folders), activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    vgg19,\n",
    "    flatten_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce757198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37298688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12522 images belonging to 67 classes.\n",
      "Found 3098 images belonging to 67 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.preprocessing.image.DirectoryIterator at 0x12b812a3220>,\n",
       " <keras.preprocessing.image.DirectoryIterator at 0x12bb6c4e2e0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255, )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('indoorCVPR_09/Images/',\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size=32,\n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = train_datagen.flow_from_directory('indoorCVPR_09/Images/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=32,\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "test_set, training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1cce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "392/392 [==============================] - 233s 596ms/step - loss: 0.2101 - accuracy: 0.9465 - val_loss: 2.6376 - val_accuracy: 0.4816\n",
      "Epoch 2/2\n",
      "392/392 [==============================] - 232s 593ms/step - loss: 0.1144 - accuracy: 0.9749 - val_loss: 2.5083 - val_accuracy: 0.5019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b811e1790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb9febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.08627451, 0.09411765, 0.22745098],\n",
       "         [0.22352941, 0.15686275, 0.23921569],\n",
       "         [0.60784314, 0.69411765, 0.78039216],\n",
       "         ...,\n",
       "         [0.43921569, 0.54117647, 0.63529412],\n",
       "         [0.49411765, 0.58431373, 0.6745098 ],\n",
       "         [0.49803922, 0.56078431, 0.65098039]],\n",
       " \n",
       "        [[0.09411765, 0.09411765, 0.23529412],\n",
       "         [0.19215686, 0.14117647, 0.21960784],\n",
       "         [0.59215686, 0.67058824, 0.76470588],\n",
       "         ...,\n",
       "         [0.60392157, 0.67058824, 0.74509804],\n",
       "         [0.45490196, 0.53333333, 0.60392157],\n",
       "         [0.43529412, 0.50196078, 0.57647059]],\n",
       " \n",
       "        [[0.10196078, 0.09411765, 0.23529412],\n",
       "         [0.16078431, 0.12941176, 0.2       ],\n",
       "         [0.50588235, 0.6       , 0.69019608],\n",
       "         ...,\n",
       "         [0.5254902 , 0.55294118, 0.63137255],\n",
       "         [0.55294118, 0.57254902, 0.63529412],\n",
       "         [0.5372549 , 0.55686275, 0.62745098]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.82352941, 0.85098039, 0.84705882],\n",
       "         [0.82745098, 0.85882353, 0.85882353],\n",
       "         [0.84313725, 0.86666667, 0.8745098 ],\n",
       "         ...,\n",
       "         [0.23137255, 0.23529412, 0.2627451 ],\n",
       "         [0.23137255, 0.25098039, 0.2627451 ],\n",
       "         [0.23137255, 0.23921569, 0.25490196]],\n",
       " \n",
       "        [[0.82745098, 0.86666667, 0.87058824],\n",
       "         [0.83137255, 0.88627451, 0.87843137],\n",
       "         [0.83921569, 0.89411765, 0.88627451],\n",
       "         ...,\n",
       "         [0.24705882, 0.24313725, 0.27843137],\n",
       "         [0.22745098, 0.25098039, 0.26666667],\n",
       "         [0.22352941, 0.23529412, 0.25098039]],\n",
       " \n",
       "        [[0.51764706, 0.46666667, 0.59607843],\n",
       "         [0.54117647, 0.50588235, 0.62352941],\n",
       "         [0.56470588, 0.54117647, 0.64313725],\n",
       "         ...,\n",
       "         [0.23921569, 0.23921569, 0.2745098 ],\n",
       "         [0.24313725, 0.22745098, 0.2627451 ],\n",
       "         [0.23921569, 0.23137255, 0.2627451 ]]]),\n",
       " (224, 224, 3))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"indoorCVPR_09\\Images\\bar\\bar_0009.jpg\")\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = img / 255.0\n",
    "img, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f4e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67,\n",
       " array([3.96047690e-04, 1.99304668e-06, 7.17860216e-09, 1.33009121e-01,\n",
       "        5.03124058e-01, 3.72388314e-07, 5.47114178e-06, 3.16909607e-03,\n",
       "        1.51304421e-05, 6.02178640e-10, 4.19404870e-03, 1.76383628e-06,\n",
       "        6.73542309e-06, 1.55395865e-05, 2.09188916e-11, 8.55204780e-05,\n",
       "        2.06443900e-03, 1.65906344e-09, 7.15348051e-07, 5.48163916e-06,\n",
       "        6.63291721e-04, 1.55160535e-07, 8.15562089e-05, 5.36712946e-07,\n",
       "        7.54216611e-02, 1.04112951e-05, 3.66595344e-07, 4.42706095e-03,\n",
       "        5.68799896e-09, 1.04932924e-05, 2.36316700e-03, 1.76158559e-04,\n",
       "        2.56220318e-07, 2.97604635e-10, 3.18573456e-07, 1.39022286e-05,\n",
       "        1.77032631e-02, 1.19412553e-05, 5.06680726e-06, 1.42009994e-05,\n",
       "        3.45519607e-06, 6.07272261e-04, 1.61990596e-04, 9.40596510e-06,\n",
       "        2.50266368e-07, 1.61853144e-08, 3.29237415e-10, 5.69572103e-06,\n",
       "        1.97974914e-05, 8.32718172e-07, 3.83366626e-07, 3.23894383e-05,\n",
       "        3.34322867e-05, 3.61501176e-11, 4.21654084e-04, 3.60398849e-06,\n",
       "        7.43911043e-03, 1.12353509e-05, 1.53561365e-02, 5.90972137e-04,\n",
       "        2.13394627e-01, 1.09806333e-05, 3.37544974e-04, 3.80627085e-07,\n",
       "        4.21641016e-05, 1.43643497e-02, 1.52922701e-04], dtype=float32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = model.predict(np.array([img]))\n",
    "len(pre[0]), pre.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1818de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(pre.flatten())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ac203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
