{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c2a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc52393",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(\"indoorCVPR_09/\", output=\"output\", seed=1337, ratio=(.7, .2, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a1ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airport_inside', 'artstudio', 'auditorium', 'bakery', 'bar']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('indoorCVPR_09/Images/*')\n",
    "categories = [folder.split(\"\\\\\")[-1] for folder in folders]\n",
    "\n",
    "categories[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fc0450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airport_inside',\n",
       " 1: 'artstudio',\n",
       " 2: 'auditorium',\n",
       " 3: 'bakery',\n",
       " 4: 'bar',\n",
       " 5: 'bathroom',\n",
       " 6: 'bedroom',\n",
       " 7: 'bookstore',\n",
       " 8: 'bowling',\n",
       " 9: 'buffet'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {}\n",
    "label_no = 0\n",
    "for category in categories:\n",
    "    labels[label_no] = category\n",
    "    label_no += 1\n",
    "\n",
    "dict(itertools.islice(labels.items(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de2cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "vgg19.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8653ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 67)                1680963   \n",
      "=================================================================\n",
      "Total params: 21,705,347\n",
      "Trainable params: 1,680,963\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = Flatten()\n",
    "prediction_layer = Dense(len(folders), activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    vgg19,\n",
    "    flatten_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce757198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37298688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12522 images belonging to 67 classes.\n",
      "Found 3098 images belonging to 67 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "training_set = datagen.flow_from_directory('indoorCVPR_09/Images/',\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size=32,\n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_set = datagen.flow_from_directory('indoorCVPR_09/Images/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=32,\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1cce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "392/392 [==============================] - 382s 944ms/step - loss: 3.1401 - accuracy: 0.3534 - val_loss: 2.5901 - val_accuracy: 0.4558\n",
      "Epoch 2/5\n",
      "392/392 [==============================] - 264s 673ms/step - loss: 0.8377 - accuracy: 0.7626 - val_loss: 2.5115 - val_accuracy: 0.4555\n",
      "Epoch 3/5\n",
      "392/392 [==============================] - 254s 647ms/step - loss: 0.3372 - accuracy: 0.9038 - val_loss: 2.7319 - val_accuracy: 0.4655\n",
      "Epoch 4/5\n",
      "392/392 [==============================] - 251s 641ms/step - loss: 0.1879 - accuracy: 0.9522 - val_loss: 2.5092 - val_accuracy: 0.4777\n",
      "Epoch 5/5\n",
      "392/392 [==============================] - 261s 666ms/step - loss: 0.1078 - accuracy: 0.9784 - val_loss: 2.4385 - val_accuracy: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220dff755b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb9febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.16078431, 0.17254902, 0.19215686],\n",
       "         [0.15686275, 0.18039216, 0.2       ],\n",
       "         [0.14509804, 0.18039216, 0.19215686],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00784314, 0.00784314, 0.03137255],\n",
       "         [0.07058824, 0.07843137, 0.10980392]],\n",
       " \n",
       "        [[0.16470588, 0.17647059, 0.19607843],\n",
       "         [0.15686275, 0.17647059, 0.19607843],\n",
       "         [0.14901961, 0.18431373, 0.19607843],\n",
       "         ...,\n",
       "         [0.07843137, 0.08627451, 0.10196078],\n",
       "         [0.16470588, 0.17647059, 0.2       ],\n",
       "         [0.18039216, 0.18823529, 0.21960784]],\n",
       " \n",
       "        [[0.16078431, 0.17647059, 0.19607843],\n",
       "         [0.15294118, 0.18039216, 0.19215686],\n",
       "         [0.15686275, 0.18431373, 0.19607843],\n",
       "         ...,\n",
       "         [0.18823529, 0.20784314, 0.21960784],\n",
       "         [0.18823529, 0.20392157, 0.22352941],\n",
       "         [0.18039216, 0.19215686, 0.22352941]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.05098039, 0.09803922, 0.11372549],\n",
       "         [0.04705882, 0.09411765, 0.10980392],\n",
       "         [0.05098039, 0.09803922, 0.11372549]],\n",
       " \n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.04705882, 0.09019608, 0.10588235],\n",
       "         [0.04313725, 0.08235294, 0.10196078],\n",
       "         [0.04705882, 0.09019608, 0.10588235]],\n",
       " \n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.04313725, 0.08627451, 0.10196078],\n",
       "         [0.03921569, 0.08235294, 0.09803922],\n",
       "         [0.04313725, 0.08627451, 0.10196078]]]),\n",
       " (224, 224, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"indoorCVPR_09\\Images\\bowling\\bowling_0132.jpg\")\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = img / 255.0\n",
    "img, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f4e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.array([img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1818de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bowling'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = labels[np.argmax(y_pred.flatten())]\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0549eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
